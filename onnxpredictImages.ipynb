{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.29  Python-3.10.13 torch-2.5.1+cpu CPU (Intel Core(TM) Ultra 7 155H)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.37...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (0.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\81915\\Desktop\\onnxrun\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "# 载入预训练模型\n",
    "model = YOLO('yolov8n.pt')\n",
    "# 保存\n",
    "success = model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size, letterbox_image):\n",
    "    \"\"\"\n",
    "        对输入图像进行resize\n",
    "    Args:\n",
    "        size:目标尺寸\n",
    "        letterbox_image: bool 是否进行letterbox变换\n",
    "    Returns:指定尺寸的图像\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    ih, iw, _ = image.shape\n",
    "    h, w = size\n",
    "    if letterbox_image:\n",
    "        scale = min(w/iw, h/ih)       # 缩放比例\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
    "        # 生成画布\n",
    "        image_back = np.ones((h, w, 3), dtype=np.uint8) * 128\n",
    "        # 将image放在画布中心区域-letterbox\n",
    "        image_back[(h-nh)//2: (h-nh)//2 + nh, (w-nw)//2:(w-nw)//2+nw, :] = image\n",
    "    else:\n",
    "        image_back = image\n",
    "    return image_back  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2input(img):\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = img/255\n",
    "    return np.expand_dims(img, axis=0).astype(np.float32)  # (1,3,640,640)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[     3.5163,      19.321,      24.027, ...,      526.32,      540.87,      567.15],\n",
      "        [     10.958,       6.117,      5.0662, ...,      588.98,      591.09,      597.43],\n",
      "        [     7.4961,       39.08,      48.835, ...,      236.43,      208.62,      164.99],\n",
      "        ...,\n",
      "        [ 3.2783e-07,  2.6822e-07,  2.6822e-07, ...,  7.1526e-07,  6.8545e-07,  1.4305e-06],\n",
      "        [ 1.4901e-07,  1.1921e-07,  8.9407e-08, ...,  9.5367e-07,  1.0133e-06,  1.2517e-06],\n",
      "        [ 3.2783e-07,  1.4901e-07,  1.1921e-07, ...,  1.3411e-06,  1.2815e-06,  1.5497e-06]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 加载ONNX模型\n",
    "ort_session = ort.InferenceSession(\"yolov8n.onnx\")\n",
    " \n",
    "\n",
    " \n",
    "# 获取输入输出的名称\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    " \n",
    "# 加载图像并预处理\n",
    "# 假设你的模型接受的是224x224大小的RGB图像，并且需要归一化到[0,1]范围\n",
    "image_path = \"two_runners1.jpg\"\n",
    "imageoringin = cv2.imread(\"two_runners1.jpg\")\n",
    "# image = Image.open(image_path).convert('RGB').resize((640, 640))\n",
    "image = resize_image(imageoringin,[640,640],1)#640, 640\n",
    "input_data = np.array(image, dtype=np.float32) / 255.0\n",
    "input_data = input_data.transpose(2, 0, 1)  # 如果模型需要NCHW格式\n",
    "input_data = np.expand_dims(input_data, axis=0)  # 增加batch维度\n",
    " \n",
    "# 进行推理\n",
    "result = ort_session.run([output_name], {input_name: input_data})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     3.5163      10.958      7.4961 ...  3.2783e-07  1.4901e-07  3.2783e-07]\n",
      " [     19.321       6.117       39.08 ...  2.6822e-07  1.1921e-07  1.4901e-07]\n",
      " [     24.027      5.0662      48.835 ...  2.6822e-07  8.9407e-08  1.1921e-07]\n",
      " ...\n",
      " [     526.32      588.98      236.43 ...  7.1526e-07  9.5367e-07  1.3411e-06]\n",
      " [     540.87      591.09      208.62 ...  6.8545e-07  1.0133e-06  1.2815e-06]\n",
      " [     567.15      597.43      164.99 ...  1.4305e-06  1.2517e-06  1.5497e-06]]\n"
     ]
    }
   ],
   "source": [
    "def std_output(pred):\n",
    "    \"\"\"\n",
    "    将（1，84，8400）处理成（8400， 85）  85= box:4  conf:1 cls:80\n",
    "    \"\"\"\n",
    "    pred = np.squeeze(pred)  # 因为只是推理，所以没有Batch\n",
    "    pred = np.transpose(pred, (1, 0))\n",
    "    pred_class = pred[..., 4:]\n",
    "    pred_conf = np.max(pred_class, axis=-1)\n",
    "    pred = np.insert(pred, 4, pred_conf, axis=-1)\n",
    "    return pred  #（8400，85）\n",
    "\n",
    "result = std_output(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([     253.19,      358.66,      107.09,      314.19,     0.92348,           0], dtype=float32), array([     383.81,      375.63,      87.379,      283.34,     0.87149,           0], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def nms(pred, conf_thres, iou_thres):\n",
    "    \"\"\"\n",
    "    非极大值抑制nms\n",
    "    Args:\n",
    "        pred: 模型输出特征图\n",
    "        conf_thres: 置信度阈值\n",
    "        iou_thres: iou阈值\n",
    "    Returns: 输出后的结果\n",
    "    \"\"\"\n",
    "    box = pred[pred[..., 4] > conf_thres]  # 置信度筛选\n",
    "    cls_conf = box[..., 5:]\n",
    "    cls = []\n",
    "    for i in range(len(cls_conf)):\n",
    "        cls.append(int(np.argmax(cls_conf[i])))\n",
    "\n",
    "    total_cls = list(set(cls))  # 记录图像内共出现几种物体\n",
    "    output_box = []\n",
    "    # 每个预测类别分开考虑\n",
    "    for i in range(len(total_cls)):\n",
    "        clss = total_cls[i]\n",
    "        cls_box = []\n",
    "        temp = box[:, :6]\n",
    "        for j in range(len(cls)):\n",
    "            # 记录[x,y,w,h,conf(最大类别概率),class]值\n",
    "            if cls[j] == clss:\n",
    "                temp[j][5] = clss\n",
    "                cls_box.append(temp[j][:6])\n",
    "        #  cls_box 里面是[x,y,w,h,conf(最大类别概率),class]\n",
    "        cls_box = np.array(cls_box)\n",
    "        sort_cls_box = sorted(cls_box, key=lambda x: -x[4])  # 将cls_box按置信度从大到小排序\n",
    "        # box_conf_sort = np.argsort(-box_conf)\n",
    "        # 得到置信度最大的预测框\n",
    "        max_conf_box = sort_cls_box[0]\n",
    "        output_box.append(max_conf_box)\n",
    "        sort_cls_box = np.delete(sort_cls_box, 0, 0)\n",
    "        # 对除max_conf_box外其他的框进行非极大值抑制\n",
    "        while len(sort_cls_box) > 0:\n",
    "            # 得到当前最大的框\n",
    "            max_conf_box = output_box[-1]\n",
    "            del_index = []\n",
    "            for j in range(len(sort_cls_box)):\n",
    "                current_box = sort_cls_box[j]\n",
    "                iou = get_iou(max_conf_box, current_box)\n",
    "                if iou > iou_thres:\n",
    "                    # 筛选出与当前最大框Iou大于阈值的框的索引\n",
    "                    del_index.append(j)\n",
    "            # 删除这些索引\n",
    "            sort_cls_box = np.delete(sort_cls_box, del_index, 0)\n",
    "            if len(sort_cls_box) > 0:\n",
    "                output_box.append(sort_cls_box[0])\n",
    "                sort_cls_box = np.delete(sort_cls_box, 0, 0)\n",
    "    return output_box\n",
    "\n",
    "\n",
    "def xywh2xyxy(*box):\n",
    "    \"\"\"\n",
    "    将xywh转换为左上角点和左下角点\n",
    "    Args:\n",
    "        box:\n",
    "    Returns: x1y1x2y2\n",
    "    \"\"\"\n",
    "    ret = [box[0] - box[2] // 2, box[1] - box[3] // 2, \\\n",
    "          box[0] + box[2] // 2, box[1] + box[3] // 2]\n",
    "    return ret\n",
    "\n",
    "def get_inter(box1, box2):\n",
    "    \"\"\"\n",
    "    计算相交部分面积\n",
    "    Args:\n",
    "        box1: 第一个框\n",
    "        box2: 第二个框\n",
    "    Returns: 相交部分的面积\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = xywh2xyxy(*box1)\n",
    "    x3, y3, x4, y4 = xywh2xyxy(*box2)\n",
    "    # 验证是否存在交集\n",
    "    if x1 >= x4 or x2 <= x3:\n",
    "        return 0\n",
    "    if y1 >= y4 or y2 <= y3:\n",
    "        return 0\n",
    "    # 将x1,x2,x3,x4排序，因为已经验证了两个框相交，所以x3-x2就是交集的宽\n",
    "    x_list = sorted([x1, x2, x3, x4])\n",
    "    x_inter = x_list[2] - x_list[1]\n",
    "    # 将y1,y2,y3,y4排序，因为已经验证了两个框相交，所以y3-y2就是交集的宽\n",
    "    y_list = sorted([y1, y2, y3, y4])\n",
    "    y_inter = y_list[2] - y_list[1]\n",
    "    # 计算交集的面积\n",
    "    inter = x_inter * y_inter\n",
    "    return inter\n",
    "\n",
    "def get_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    计算交并比： (A n B)/(A + B - A n B)\n",
    "    Args:\n",
    "        box1: 第一个框\n",
    "        box2: 第二个框\n",
    "    Returns:  # 返回交并比的值\n",
    "    \"\"\"\n",
    "    box1_area = box1[2] * box1[3]  # 计算第一个框的面积\n",
    "    box2_area = box2[2] * box2[3]  # 计算第二个框的面积\n",
    "    inter_area = get_inter(box1, box2)\n",
    "    union = box1_area + box2_area - inter_area   #(A n B)/(A + B - A n B)\n",
    "    iou = inter_area / union\n",
    "    return iou\n",
    "result = nms(result, 0.5, 0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     1655.6      791.14      2532.3        3388     0.92348           0]\n",
      " [     2818.6      1063.8      3529.9        3396     0.87149           0]]\n"
     ]
    }
   ],
   "source": [
    "def cod_trf(result, pre, after):\n",
    "    \"\"\"\n",
    "    因为预测框是在经过letterbox后的图像上做预测所以需要将预测框的坐标映射回原图像上\n",
    "    Args:\n",
    "        result:  [x,y,w,h,conf(最大类别概率),class]\n",
    "        pre:    原尺寸图像\n",
    "        after:  经过letterbox处理后的图像\n",
    "    Returns: 坐标变换后的结果,并将xywh转换为左上角右下角坐标x1y1x2y2\n",
    "    \"\"\"\n",
    "    res = np.array(result)\n",
    "    x, y, w, h, conf, cls = res.transpose((1, 0))\n",
    "    x1, y1, x2, y2 = xywh2xyxy(x, y, w, h)  # 左上角点和右下角的点\n",
    "    h_pre, w_pre, _ = pre.shape\n",
    "    h_after, w_after, _ = after.shape\n",
    "    scale = max(w_pre/w_after, h_pre/h_after)  # 缩放比例\n",
    "    h_pre, w_pre = h_pre/scale, w_pre/scale  # 计算原图在等比例缩放后的尺寸\n",
    "    x_move, y_move = abs(w_pre-w_after)//2, abs(h_pre-h_after)//2  # 计算平移的量\n",
    "    ret_x1, ret_x2 = (x1 - x_move) * scale, (x2 - x_move) * scale\n",
    "    ret_y1, ret_y2 = (y1 - y_move) * scale, (y2 - y_move) * scale\n",
    "    ret = np.array([ret_x1, ret_y1, ret_x2, ret_y2, conf, cls]).transpose((1, 0))\n",
    "    return ret  # x1y1x2y2\n",
    "ret = cod_trf(result, imageoringin, image)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(res, image, cls):\n",
    "    \"\"\"\n",
    "    将预测框绘制在image上\n",
    "    Args:\n",
    "        res: 预测框数据\n",
    "        image: 原图\n",
    "        cls: 类别列表，类似[\"apple\", \"banana\", \"people\"]  可以自己设计或者通过数据集的yaml文件获取\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for r in res:\n",
    "        # 画框\n",
    "        image = cv2.rectangle(image, (int(r[0]), int(r[1])), (int(r[2]), int(r[3])), (255, 0, 0), 1)\n",
    "        # 表明类别\n",
    "        if r[5]<10:\n",
    "        \n",
    "            text = \"{}:{}\".format(cls[int(r[5])], \\\n",
    "                                round(float(r[4]), 2))\n",
    "            h, w = int(r[3]) - int(r[1]), int(r[2]) - int(r[0])  # 计算预测框的长宽\n",
    "            font_size = min(h/640, w/640) * 3  # 计算字体大小（随框大小调整）\n",
    "            image = cv2.putText(image, text, (max(10, int(r[0])), max(20, int(r[1]))), cv2.FONT_HERSHEY_COMPLEX, max(font_size, 0.3), (0, 0, 255), 1)   # max()为了确保字体不过界\n",
    "    # cv2.imshow(\"result\", image)\n",
    "    # cv2.waitKey()\n",
    "    # cv2.destroyWindow(\"result\")\n",
    "    cv2.imwrite('output_image.jpg', image)\n",
    "\n",
    "draw(ret,imageoringin,[\"people\",\"2\",\"3\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo888",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
